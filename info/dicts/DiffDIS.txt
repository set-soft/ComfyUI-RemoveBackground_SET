Analyzing: ../../models/diffdis/unet/diffusion_pytorch_model.safetensors

--- PyTorch Model Keys ---


rgb_conv.0.1.num_batches_tracked []
rgb_conv.1.1.num_batches_tracked []
rgb_conv.2.1.num_batches_tracked []
class_embedding.linear_1.bias [1280]
class_embedding.linear_1.weight [1280, 4]
class_embedding.linear_2.bias [1280]
class_embedding.linear_2.weight [1280, 1280]
conv_in.bias [320]
conv_in.weight [320, 8, 3, 3]
conv_norm_out.bias [320]
conv_norm_out.weight [320]
conv_out.bias [4]
conv_out.weight [4, 320, 3, 3]
down_blocks.0.attentions.0.norm.bias [320]
down_blocks.0.attentions.0.norm.weight [320]
down_blocks.0.attentions.0.proj_in.bias [320]
down_blocks.0.attentions.0.proj_in.weight [320, 320]
down_blocks.0.attentions.0.proj_out.bias [320]
down_blocks.0.attentions.0.proj_out.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight [320, 1024]
down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight [320, 320]
down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight [320, 1024]
down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [2560]
down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [2560, 320]
down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight [320, 1280]
down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight [320]
down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight [320]
down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias [320]
down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight [320]
down_blocks.0.attentions.1.norm.bias [320]
down_blocks.0.attentions.1.norm.weight [320]
down_blocks.0.attentions.1.proj_in.bias [320]
down_blocks.0.attentions.1.proj_in.weight [320, 320]
down_blocks.0.attentions.1.proj_out.bias [320]
down_blocks.0.attentions.1.proj_out.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight [320, 1024]
down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight [320, 320]
down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight [320, 1024]
down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [2560]
down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [2560, 320]
down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight [320, 1280]
down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight [320]
down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight [320]
down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias [320]
down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight [320]
down_blocks.0.downsamplers.0.conv.bias [320]
down_blocks.0.downsamplers.0.conv.weight [320, 320, 3, 3]
down_blocks.0.resnets.0.conv1.bias [320]
down_blocks.0.resnets.0.conv1.weight [320, 320, 3, 3]
down_blocks.0.resnets.0.conv2.bias [320]
down_blocks.0.resnets.0.conv2.weight [320, 320, 3, 3]
down_blocks.0.resnets.0.norm1.bias [320]
down_blocks.0.resnets.0.norm1.weight [320]
down_blocks.0.resnets.0.norm2.bias [320]
down_blocks.0.resnets.0.norm2.weight [320]
down_blocks.0.resnets.0.time_emb_proj.bias [320]
down_blocks.0.resnets.0.time_emb_proj.weight [320, 1280]
down_blocks.0.resnets.1.conv1.bias [320]
down_blocks.0.resnets.1.conv1.weight [320, 320, 3, 3]
down_blocks.0.resnets.1.conv2.bias [320]
down_blocks.0.resnets.1.conv2.weight [320, 320, 3, 3]
down_blocks.0.resnets.1.norm1.bias [320]
down_blocks.0.resnets.1.norm1.weight [320]
down_blocks.0.resnets.1.norm2.bias [320]
down_blocks.0.resnets.1.norm2.weight [320]
down_blocks.0.resnets.1.time_emb_proj.bias [320]
down_blocks.0.resnets.1.time_emb_proj.weight [320, 1280]
down_blocks.1.attentions.0.norm.bias [640]
down_blocks.1.attentions.0.norm.weight [640]
down_blocks.1.attentions.0.proj_in.bias [640]
down_blocks.1.attentions.0.proj_in.weight [640, 640]
down_blocks.1.attentions.0.proj_out.bias [640]
down_blocks.1.attentions.0.proj_out.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight [640, 1024]
down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight [640, 640]
down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight [640, 1024]
down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [5120]
down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [5120, 640]
down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight [640, 2560]
down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight [640]
down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight [640]
down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias [640]
down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight [640]
down_blocks.1.attentions.1.norm.bias [640]
down_blocks.1.attentions.1.norm.weight [640]
down_blocks.1.attentions.1.proj_in.bias [640]
down_blocks.1.attentions.1.proj_in.weight [640, 640]
down_blocks.1.attentions.1.proj_out.bias [640]
down_blocks.1.attentions.1.proj_out.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight [640, 1024]
down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight [640, 640]
down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight [640, 1024]
down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [5120]
down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [5120, 640]
down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight [640, 2560]
down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight [640]
down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight [640]
down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias [640]
down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight [640]
down_blocks.1.downsamplers.0.conv.bias [640]
down_blocks.1.downsamplers.0.conv.weight [640, 640, 3, 3]
down_blocks.1.resnets.0.conv1.bias [640]
down_blocks.1.resnets.0.conv1.weight [640, 320, 3, 3]
down_blocks.1.resnets.0.conv2.bias [640]
down_blocks.1.resnets.0.conv2.weight [640, 640, 3, 3]
down_blocks.1.resnets.0.conv_shortcut.bias [640]
down_blocks.1.resnets.0.conv_shortcut.weight [640, 320, 1, 1]
down_blocks.1.resnets.0.norm1.bias [320]
down_blocks.1.resnets.0.norm1.weight [320]
down_blocks.1.resnets.0.norm2.bias [640]
down_blocks.1.resnets.0.norm2.weight [640]
down_blocks.1.resnets.0.time_emb_proj.bias [640]
down_blocks.1.resnets.0.time_emb_proj.weight [640, 1280]
down_blocks.1.resnets.1.conv1.bias [640]
down_blocks.1.resnets.1.conv1.weight [640, 640, 3, 3]
down_blocks.1.resnets.1.conv2.bias [640]
down_blocks.1.resnets.1.conv2.weight [640, 640, 3, 3]
down_blocks.1.resnets.1.norm1.bias [640]
down_blocks.1.resnets.1.norm1.weight [640]
down_blocks.1.resnets.1.norm2.bias [640]
down_blocks.1.resnets.1.norm2.weight [640]
down_blocks.1.resnets.1.time_emb_proj.bias [640]
down_blocks.1.resnets.1.time_emb_proj.weight [640, 1280]
down_blocks.2.attentions.0.norm.bias [1280]
down_blocks.2.attentions.0.norm.weight [1280]
down_blocks.2.attentions.0.proj_in.bias [1280]
down_blocks.2.attentions.0.proj_in.weight [1280, 1280]
down_blocks.2.attentions.0.proj_out.bias [1280]
down_blocks.2.attentions.0.proj_out.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [10240]
down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight [1280, 5120]
down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight [1280]
down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight [1280]
down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias [1280]
down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight [1280]
down_blocks.2.attentions.1.norm.bias [1280]
down_blocks.2.attentions.1.norm.weight [1280]
down_blocks.2.attentions.1.proj_in.bias [1280]
down_blocks.2.attentions.1.proj_in.weight [1280, 1280]
down_blocks.2.attentions.1.proj_out.bias [1280]
down_blocks.2.attentions.1.proj_out.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [10240]
down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight [1280, 5120]
down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight [1280]
down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight [1280]
down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias [1280]
down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight [1280]
down_blocks.2.downsamplers.0.conv.bias [1280]
down_blocks.2.downsamplers.0.conv.weight [1280, 1280, 3, 3]
down_blocks.2.resnets.0.conv1.bias [1280]
down_blocks.2.resnets.0.conv1.weight [1280, 640, 3, 3]
down_blocks.2.resnets.0.conv2.bias [1280]
down_blocks.2.resnets.0.conv2.weight [1280, 1280, 3, 3]
down_blocks.2.resnets.0.conv_shortcut.bias [1280]
down_blocks.2.resnets.0.conv_shortcut.weight [1280, 640, 1, 1]
down_blocks.2.resnets.0.norm1.bias [640]
down_blocks.2.resnets.0.norm1.weight [640]
down_blocks.2.resnets.0.norm2.bias [1280]
down_blocks.2.resnets.0.norm2.weight [1280]
down_blocks.2.resnets.0.time_emb_proj.bias [1280]
down_blocks.2.resnets.0.time_emb_proj.weight [1280, 1280]
down_blocks.2.resnets.1.conv1.bias [1280]
down_blocks.2.resnets.1.conv1.weight [1280, 1280, 3, 3]
down_blocks.2.resnets.1.conv2.bias [1280]
down_blocks.2.resnets.1.conv2.weight [1280, 1280, 3, 3]
down_blocks.2.resnets.1.norm1.bias [1280]
down_blocks.2.resnets.1.norm1.weight [1280]
down_blocks.2.resnets.1.norm2.bias [1280]
down_blocks.2.resnets.1.norm2.weight [1280]
down_blocks.2.resnets.1.time_emb_proj.bias [1280]
down_blocks.2.resnets.1.time_emb_proj.weight [1280, 1280]
down_blocks.3.resnets.0.conv1.bias [1280]
down_blocks.3.resnets.0.conv1.weight [1280, 1280, 3, 3]
down_blocks.3.resnets.0.conv2.bias [1280]
down_blocks.3.resnets.0.conv2.weight [1280, 1280, 3, 3]
down_blocks.3.resnets.0.norm1.bias [1280]
down_blocks.3.resnets.0.norm1.weight [1280]
down_blocks.3.resnets.0.norm2.bias [1280]
down_blocks.3.resnets.0.norm2.weight [1280]
down_blocks.3.resnets.0.time_emb_proj.bias [1280]
down_blocks.3.resnets.0.time_emb_proj.weight [1280, 1280]
down_blocks.3.resnets.1.conv1.bias [1280]
down_blocks.3.resnets.1.conv1.weight [1280, 1280, 3, 3]
down_blocks.3.resnets.1.conv2.bias [1280]
down_blocks.3.resnets.1.conv2.weight [1280, 1280, 3, 3]
down_blocks.3.resnets.1.norm1.bias [1280]
down_blocks.3.resnets.1.norm1.weight [1280]
down_blocks.3.resnets.1.norm2.bias [1280]
down_blocks.3.resnets.1.norm2.weight [1280]
down_blocks.3.resnets.1.time_emb_proj.bias [1280]
down_blocks.3.resnets.1.time_emb_proj.weight [1280, 1280]
mid_block.attentions.0.norm.bias [1280]
mid_block.attentions.0.norm.weight [1280]
mid_block.attentions.0.proj_in.bias [1280]
mid_block.attentions.0.proj_in.weight [1280, 1280]
mid_block.attentions.0.proj_out.bias [1280]
mid_block.attentions.0.proj_out.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [1280]
mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [1280]
mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
mid_block.attentions.0.transformer_blocks.0.attn3.to_k.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn3.to_out.0.bias [1280]
mid_block.attentions.0.transformer_blocks.0.attn3.to_out.0.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn3.to_q.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.attn3.to_v.weight [1280, 1280]
mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [10240]
mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias [1280]
mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight [1280, 5120]
mid_block.attentions.0.transformer_blocks.0.norm1.bias [1280]
mid_block.attentions.0.transformer_blocks.0.norm1.weight [1280]
mid_block.attentions.0.transformer_blocks.0.norm2.bias [1280]
mid_block.attentions.0.transformer_blocks.0.norm2.weight [1280]
mid_block.attentions.0.transformer_blocks.0.norm2_.bias [1280]
mid_block.attentions.0.transformer_blocks.0.norm2_.weight [1280]
mid_block.attentions.0.transformer_blocks.0.norm3.bias [1280]
mid_block.attentions.0.transformer_blocks.0.norm3.weight [1280]
mid_block.resnets.0.conv1.bias [1280]
mid_block.resnets.0.conv1.weight [1280, 1280, 3, 3]
mid_block.resnets.0.conv2.bias [1280]
mid_block.resnets.0.conv2.weight [1280, 1280, 3, 3]
mid_block.resnets.0.norm1.bias [1280]
mid_block.resnets.0.norm1.weight [1280]
mid_block.resnets.0.norm2.bias [1280]
mid_block.resnets.0.norm2.weight [1280]
mid_block.resnets.0.time_emb_proj.bias [1280]
mid_block.resnets.0.time_emb_proj.weight [1280, 1280]
mid_block.resnets.1.conv1.bias [1280]
mid_block.resnets.1.conv1.weight [1280, 1280, 3, 3]
mid_block.resnets.1.conv2.bias [1280]
mid_block.resnets.1.conv2.weight [1280, 1280, 3, 3]
mid_block.resnets.1.norm1.bias [1280]
mid_block.resnets.1.norm1.weight [1280]
mid_block.resnets.1.norm2.bias [1280]
mid_block.resnets.1.norm2.weight [1280]
mid_block.resnets.1.time_emb_proj.bias [1280]
mid_block.resnets.1.time_emb_proj.weight [1280, 1280]
rgb_conv.0.0.bias [320]
rgb_conv.0.0.weight [320, 4, 3, 3]
rgb_conv.0.1.bias [320]
rgb_conv.0.1.running_mean [320]
rgb_conv.0.1.running_var [320]
rgb_conv.0.1.weight [320]
rgb_conv.1.0.bias [640]
rgb_conv.1.0.weight [640, 4, 3, 3]
rgb_conv.1.1.bias [640]
rgb_conv.1.1.running_mean [640]
rgb_conv.1.1.running_var [640]
rgb_conv.1.1.weight [640]
rgb_conv.2.0.bias [1280]
rgb_conv.2.0.weight [1280, 4, 3, 3]
rgb_conv.2.1.bias [1280]
rgb_conv.2.1.running_mean [1280]
rgb_conv.2.1.running_var [1280]
rgb_conv.2.1.weight [1280]
rgb_proj.0.bias [320]
rgb_proj.0.weight [320, 320, 3, 3]
rgb_proj.1.bias [640]
rgb_proj.1.weight [640, 640, 3, 3]
rgb_proj.2.bias [1280]
rgb_proj.2.weight [1280, 1280, 3, 3]
rgb_proj1.0.bias [320]
rgb_proj1.0.weight [320, 320, 3, 3]
rgb_proj1.1.bias [640]
rgb_proj1.1.weight [640, 640, 3, 3]
rgb_proj1.2.bias [1280]
rgb_proj1.2.weight [1280, 1280, 3, 3]
time_embedding.linear_1.bias [1280]
time_embedding.linear_1.weight [1280, 320]
time_embedding.linear_2.bias [1280]
time_embedding.linear_2.weight [1280, 1280]
up_blocks.0.resnets.0.conv1.bias [1280]
up_blocks.0.resnets.0.conv1.weight [1280, 2560, 3, 3]
up_blocks.0.resnets.0.conv2.bias [1280]
up_blocks.0.resnets.0.conv2.weight [1280, 1280, 3, 3]
up_blocks.0.resnets.0.conv_shortcut.bias [1280]
up_blocks.0.resnets.0.conv_shortcut.weight [1280, 2560, 1, 1]
up_blocks.0.resnets.0.norm1.bias [2560]
up_blocks.0.resnets.0.norm1.weight [2560]
up_blocks.0.resnets.0.norm2.bias [1280]
up_blocks.0.resnets.0.norm2.weight [1280]
up_blocks.0.resnets.0.time_emb_proj.bias [1280]
up_blocks.0.resnets.0.time_emb_proj.weight [1280, 1280]
up_blocks.0.resnets.1.conv1.bias [1280]
up_blocks.0.resnets.1.conv1.weight [1280, 2560, 3, 3]
up_blocks.0.resnets.1.conv2.bias [1280]
up_blocks.0.resnets.1.conv2.weight [1280, 1280, 3, 3]
up_blocks.0.resnets.1.conv_shortcut.bias [1280]
up_blocks.0.resnets.1.conv_shortcut.weight [1280, 2560, 1, 1]
up_blocks.0.resnets.1.norm1.bias [2560]
up_blocks.0.resnets.1.norm1.weight [2560]
up_blocks.0.resnets.1.norm2.bias [1280]
up_blocks.0.resnets.1.norm2.weight [1280]
up_blocks.0.resnets.1.time_emb_proj.bias [1280]
up_blocks.0.resnets.1.time_emb_proj.weight [1280, 1280]
up_blocks.0.resnets.2.conv1.bias [1280]
up_blocks.0.resnets.2.conv1.weight [1280, 2560, 3, 3]
up_blocks.0.resnets.2.conv2.bias [1280]
up_blocks.0.resnets.2.conv2.weight [1280, 1280, 3, 3]
up_blocks.0.resnets.2.conv_shortcut.bias [1280]
up_blocks.0.resnets.2.conv_shortcut.weight [1280, 2560, 1, 1]
up_blocks.0.resnets.2.norm1.bias [2560]
up_blocks.0.resnets.2.norm1.weight [2560]
up_blocks.0.resnets.2.norm2.bias [1280]
up_blocks.0.resnets.2.norm2.weight [1280]
up_blocks.0.resnets.2.time_emb_proj.bias [1280]
up_blocks.0.resnets.2.time_emb_proj.weight [1280, 1280]
up_blocks.0.upsamplers.0.conv.bias [1280]
up_blocks.0.upsamplers.0.conv.weight [1280, 1280, 3, 3]
up_blocks.1.attentions.0.norm.bias [1280]
up_blocks.1.attentions.0.norm.weight [1280]
up_blocks.1.attentions.0.proj_in.bias [1280]
up_blocks.1.attentions.0.proj_in.weight [1280, 1280]
up_blocks.1.attentions.0.proj_out.bias [1280]
up_blocks.1.attentions.0.proj_out.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [10240]
up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight [1280, 5120]
up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight [1280]
up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight [1280]
up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias [1280]
up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight [1280]
up_blocks.1.attentions.1.norm.bias [1280]
up_blocks.1.attentions.1.norm.weight [1280]
up_blocks.1.attentions.1.proj_in.bias [1280]
up_blocks.1.attentions.1.proj_in.weight [1280, 1280]
up_blocks.1.attentions.1.proj_out.bias [1280]
up_blocks.1.attentions.1.proj_out.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [10240]
up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight [1280, 5120]
up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight [1280]
up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight [1280]
up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias [1280]
up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight [1280]
up_blocks.1.attentions.2.norm.bias [1280]
up_blocks.1.attentions.2.norm.weight [1280]
up_blocks.1.attentions.2.proj_in.bias [1280]
up_blocks.1.attentions.2.proj_in.weight [1280, 1280]
up_blocks.1.attentions.2.proj_out.bias [1280]
up_blocks.1.attentions.2.proj_out.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight [1280, 1024]
up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight [1280, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight [1280, 1024]
up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias [10240]
up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight [10240, 1280]
up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight [1280, 5120]
up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight [1280]
up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight [1280]
up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias [1280]
up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight [1280]
up_blocks.1.resnets.0.conv1.bias [1280]
up_blocks.1.resnets.0.conv1.weight [1280, 2560, 3, 3]
up_blocks.1.resnets.0.conv2.bias [1280]
up_blocks.1.resnets.0.conv2.weight [1280, 1280, 3, 3]
up_blocks.1.resnets.0.conv_shortcut.bias [1280]
up_blocks.1.resnets.0.conv_shortcut.weight [1280, 2560, 1, 1]
up_blocks.1.resnets.0.norm1.bias [2560]
up_blocks.1.resnets.0.norm1.weight [2560]
up_blocks.1.resnets.0.norm2.bias [1280]
up_blocks.1.resnets.0.norm2.weight [1280]
up_blocks.1.resnets.0.time_emb_proj.bias [1280]
up_blocks.1.resnets.0.time_emb_proj.weight [1280, 1280]
up_blocks.1.resnets.1.conv1.bias [1280]
up_blocks.1.resnets.1.conv1.weight [1280, 2560, 3, 3]
up_blocks.1.resnets.1.conv2.bias [1280]
up_blocks.1.resnets.1.conv2.weight [1280, 1280, 3, 3]
up_blocks.1.resnets.1.conv_shortcut.bias [1280]
up_blocks.1.resnets.1.conv_shortcut.weight [1280, 2560, 1, 1]
up_blocks.1.resnets.1.norm1.bias [2560]
up_blocks.1.resnets.1.norm1.weight [2560]
up_blocks.1.resnets.1.norm2.bias [1280]
up_blocks.1.resnets.1.norm2.weight [1280]
up_blocks.1.resnets.1.time_emb_proj.bias [1280]
up_blocks.1.resnets.1.time_emb_proj.weight [1280, 1280]
up_blocks.1.resnets.2.conv1.bias [1280]
up_blocks.1.resnets.2.conv1.weight [1280, 1920, 3, 3]
up_blocks.1.resnets.2.conv2.bias [1280]
up_blocks.1.resnets.2.conv2.weight [1280, 1280, 3, 3]
up_blocks.1.resnets.2.conv_shortcut.bias [1280]
up_blocks.1.resnets.2.conv_shortcut.weight [1280, 1920, 1, 1]
up_blocks.1.resnets.2.norm1.bias [1920]
up_blocks.1.resnets.2.norm1.weight [1920]
up_blocks.1.resnets.2.norm2.bias [1280]
up_blocks.1.resnets.2.norm2.weight [1280]
up_blocks.1.resnets.2.time_emb_proj.bias [1280]
up_blocks.1.resnets.2.time_emb_proj.weight [1280, 1280]
up_blocks.1.upsamplers.0.conv.bias [1280]
up_blocks.1.upsamplers.0.conv.weight [1280, 1280, 3, 3]
up_blocks.2.attentions.0.norm.bias [640]
up_blocks.2.attentions.0.norm.weight [640]
up_blocks.2.attentions.0.proj_in.bias [640]
up_blocks.2.attentions.0.proj_in.weight [640, 640]
up_blocks.2.attentions.0.proj_out.bias [640]
up_blocks.2.attentions.0.proj_out.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight [640, 1024]
up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight [640, 640]
up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight [640, 1024]
up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [5120]
up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [5120, 640]
up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight [640, 2560]
up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight [640]
up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight [640]
up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias [640]
up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight [640]
up_blocks.2.attentions.1.norm.bias [640]
up_blocks.2.attentions.1.norm.weight [640]
up_blocks.2.attentions.1.proj_in.bias [640]
up_blocks.2.attentions.1.proj_in.weight [640, 640]
up_blocks.2.attentions.1.proj_out.bias [640]
up_blocks.2.attentions.1.proj_out.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight [640, 1024]
up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight [640, 640]
up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight [640, 1024]
up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [5120]
up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [5120, 640]
up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight [640, 2560]
up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight [640]
up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight [640]
up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias [640]
up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight [640]
up_blocks.2.attentions.2.norm.bias [640]
up_blocks.2.attentions.2.norm.weight [640]
up_blocks.2.attentions.2.proj_in.bias [640]
up_blocks.2.attentions.2.proj_in.weight [640, 640]
up_blocks.2.attentions.2.proj_out.bias [640]
up_blocks.2.attentions.2.proj_out.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight [640, 1024]
up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight [640, 640]
up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight [640, 1024]
up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias [5120]
up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight [5120, 640]
up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight [640, 2560]
up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight [640]
up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight [640]
up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias [640]
up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight [640]
up_blocks.2.resnets.0.conv1.bias [640]
up_blocks.2.resnets.0.conv1.weight [640, 1920, 3, 3]
up_blocks.2.resnets.0.conv2.bias [640]
up_blocks.2.resnets.0.conv2.weight [640, 640, 3, 3]
up_blocks.2.resnets.0.conv_shortcut.bias [640]
up_blocks.2.resnets.0.conv_shortcut.weight [640, 1920, 1, 1]
up_blocks.2.resnets.0.norm1.bias [1920]
up_blocks.2.resnets.0.norm1.weight [1920]
up_blocks.2.resnets.0.norm2.bias [640]
up_blocks.2.resnets.0.norm2.weight [640]
up_blocks.2.resnets.0.time_emb_proj.bias [640]
up_blocks.2.resnets.0.time_emb_proj.weight [640, 1280]
up_blocks.2.resnets.1.conv1.bias [640]
up_blocks.2.resnets.1.conv1.weight [640, 1280, 3, 3]
up_blocks.2.resnets.1.conv2.bias [640]
up_blocks.2.resnets.1.conv2.weight [640, 640, 3, 3]
up_blocks.2.resnets.1.conv_shortcut.bias [640]
up_blocks.2.resnets.1.conv_shortcut.weight [640, 1280, 1, 1]
up_blocks.2.resnets.1.norm1.bias [1280]
up_blocks.2.resnets.1.norm1.weight [1280]
up_blocks.2.resnets.1.norm2.bias [640]
up_blocks.2.resnets.1.norm2.weight [640]
up_blocks.2.resnets.1.time_emb_proj.bias [640]
up_blocks.2.resnets.1.time_emb_proj.weight [640, 1280]
up_blocks.2.resnets.2.conv1.bias [640]
up_blocks.2.resnets.2.conv1.weight [640, 960, 3, 3]
up_blocks.2.resnets.2.conv2.bias [640]
up_blocks.2.resnets.2.conv2.weight [640, 640, 3, 3]
up_blocks.2.resnets.2.conv_shortcut.bias [640]
up_blocks.2.resnets.2.conv_shortcut.weight [640, 960, 1, 1]
up_blocks.2.resnets.2.norm1.bias [960]
up_blocks.2.resnets.2.norm1.weight [960]
up_blocks.2.resnets.2.norm2.bias [640]
up_blocks.2.resnets.2.norm2.weight [640]
up_blocks.2.resnets.2.time_emb_proj.bias [640]
up_blocks.2.resnets.2.time_emb_proj.weight [640, 1280]
up_blocks.2.upsamplers.0.conv.bias [640]
up_blocks.2.upsamplers.0.conv.weight [640, 640, 3, 3]
up_blocks.3.attentions.0.norm.bias [320]
up_blocks.3.attentions.0.norm.weight [320]
up_blocks.3.attentions.0.proj_in.bias [320]
up_blocks.3.attentions.0.proj_in.weight [320, 320]
up_blocks.3.attentions.0.proj_out.bias [320]
up_blocks.3.attentions.0.proj_out.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight [320, 1024]
up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight [320, 320]
up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight [320, 1024]
up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias [2560]
up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight [2560, 320]
up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight [320, 1280]
up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight [320]
up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight [320]
up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias [320]
up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight [320]
up_blocks.3.attentions.1.norm.bias [320]
up_blocks.3.attentions.1.norm.weight [320]
up_blocks.3.attentions.1.proj_in.bias [320]
up_blocks.3.attentions.1.proj_in.weight [320, 320]
up_blocks.3.attentions.1.proj_out.bias [320]
up_blocks.3.attentions.1.proj_out.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight [320, 1024]
up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight [320, 320]
up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight [320, 1024]
up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias [2560]
up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight [2560, 320]
up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight [320, 1280]
up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight [320]
up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight [320]
up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias [320]
up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight [320]
up_blocks.3.attentions.2.norm.bias [320]
up_blocks.3.attentions.2.norm.weight [320]
up_blocks.3.attentions.2.proj_in.bias [320]
up_blocks.3.attentions.2.proj_in.weight [320, 320]
up_blocks.3.attentions.2.proj_out.bias [320]
up_blocks.3.attentions.2.proj_out.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight [320, 1024]
up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight [320, 320]
up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight [320, 1024]
up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias [2560]
up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight [2560, 320]
up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight [320, 1280]
up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight [320]
up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight [320]
up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias [320]
up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight [320]
up_blocks.3.resnets.0.conv1.bias [320]
up_blocks.3.resnets.0.conv1.weight [320, 960, 3, 3]
up_blocks.3.resnets.0.conv2.bias [320]
up_blocks.3.resnets.0.conv2.weight [320, 320, 3, 3]
up_blocks.3.resnets.0.conv_shortcut.bias [320]
up_blocks.3.resnets.0.conv_shortcut.weight [320, 960, 1, 1]
up_blocks.3.resnets.0.norm1.bias [960]
up_blocks.3.resnets.0.norm1.weight [960]
up_blocks.3.resnets.0.norm2.bias [320]
up_blocks.3.resnets.0.norm2.weight [320]
up_blocks.3.resnets.0.time_emb_proj.bias [320]
up_blocks.3.resnets.0.time_emb_proj.weight [320, 1280]
up_blocks.3.resnets.1.conv1.bias [320]
up_blocks.3.resnets.1.conv1.weight [320, 640, 3, 3]
up_blocks.3.resnets.1.conv2.bias [320]
up_blocks.3.resnets.1.conv2.weight [320, 320, 3, 3]
up_blocks.3.resnets.1.conv_shortcut.bias [320]
up_blocks.3.resnets.1.conv_shortcut.weight [320, 640, 1, 1]
up_blocks.3.resnets.1.norm1.bias [640]
up_blocks.3.resnets.1.norm1.weight [640]
up_blocks.3.resnets.1.norm2.bias [320]
up_blocks.3.resnets.1.norm2.weight [320]
up_blocks.3.resnets.1.time_emb_proj.bias [320]
up_blocks.3.resnets.1.time_emb_proj.weight [320, 1280]
up_blocks.3.resnets.2.conv1.bias [320]
up_blocks.3.resnets.2.conv1.weight [320, 640, 3, 3]
up_blocks.3.resnets.2.conv2.bias [320]
up_blocks.3.resnets.2.conv2.weight [320, 320, 3, 3]
up_blocks.3.resnets.2.conv_shortcut.bias [320]
up_blocks.3.resnets.2.conv_shortcut.weight [320, 640, 1, 1]
up_blocks.3.resnets.2.norm1.bias [640]
up_blocks.3.resnets.2.norm1.weight [640]
up_blocks.3.resnets.2.norm2.bias [320]
up_blocks.3.resnets.2.norm2.weight [320]
up_blocks.3.resnets.2.time_emb_proj.bias [320]
up_blocks.3.resnets.2.time_emb_proj.weight [320, 1280]
